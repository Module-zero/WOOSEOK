# 모듈 0 - 알고리즘

## <em>2020-10-05(월) ~</em>

* 진도
    * 2020-10-05(월) : 알고리즘 시작, 자료구조 1
    * 2020-10-06(화) : 수학 1
    * 2020-10-07(수) : 밀린 문제 풀이
    * 2020-10-09(금) : 다이나믹 프로그래밍 1
    
    * 2020-10-13(화) : 다이나믹 프로그래밍 1 _기초 1/2 종료_
    * 2020-10-14(수) : 브루트 포스 - 브루트 포스, N과 M, 순열
    * 2020-10-15(목) : 브루트 포스 - 재귀, 비트마스크
    * 2020-10-16(금) : 그래프 1
    
    * 2020-10-20(화) : BFS, 트리 1 _기초 2/2 종료_
    * 2020-10-21(수) : 밀린 문제 풀이
    * 2020-10-22(목) : 밀린 문제 풀이
    * 2020-10-23(금) : 밀린 문제 풀이
    
    * 2020-10-27(화) : 브루트 포스 중급
    * 2020-10-28(수) : BFS 중급
    * 2020-10-29(목) : 그리디
    * 2020-10-30(금) : 그리디
    
    * 2020-11-03(화) : 분할 정복
    * 2020-11-04(수) : 정렬
    * 2020-11-05(목) : 이분 탐색 _중급 1/3 종료_
    * 2020-11-06(금) : 밀린 문제 풀이
    
* 정리
    * _2020-10-07(수)_
        * String 객체는 +=을 할 때마다 기존의 내용을 복사해서 새로운 객체를 만든다.
    
    * _2020-10-08(목)_
        * String 객체의 toCharArray()보다 charAt()이 더 빠르다.
        * StringBuilder 객체의 insert()는 굉장히 느리다.
        
    * _2020-10-20(화)_
        * BFS는 큐에 넣은 것을 방문한 것으로 친다.(중복 문제 발생할 수 있음)
        * DFS는 특정 조합을 만들어 내야 하는 경우에 주로 사용된다.
        * BFS는 0 또는 1로 이루어진 그래프를 풀 때 사용할 수 있다.(최단 경로)
        * 트리의 조건 : 정점의 개수가 V일 때, 간선의 개수가 V-1이며 모든 정점이 연결
        * 트리에서 포스트 오더(후위 순회)가 가장 중요하다.
        
    * _2020-10-24(토)_
        * 그래프 문제를 풀 때 리스트를 사용하는 것이 배열을 사용하는 것보다 공간 복잡도가 적다.
        
    * _2020-10-27(화)_
        * 백트래킹 : 브루트 포스와 비슷하지만 가능성이 없으면 중간에 잘라낸다.
        * 브루트포스에서 재귀를 사용하고 이후의 값이 이전의 값에 영향을 받지 않는 경우 dp를 사용할 수 있다.
        * 출력 양식에 띄어쓰기가 있을 경우 String을 직접 더하지 말고 StringBuilder의 append를 사용하자.
        
    * _2020-10-29(목)_
        * 배열을 선언할 때 최대치로 선언하든 변수로 선언하든 큰 차이가 없다.(오히려 변수로 선언한 게 경우에 따라 시간복잡도가 느릴 수 있다.)
        
    * _2020-11-04(수)_
        * 자바에서는 Arrays.sort가 O(N^2)의 시간 복잡도를 가지므로 배열을 섞고 Arrays.sort를 사용하던지 Collections.sort를 사용하는 것이 무조건 좋다.
        * 이분 탐색으로 정답을 찾는 것이 가능한 문제는 어떤 기준으로 Yes/No로 나뉘는 문제이다.
    * _2020-11-09(월)_
        * String의 compareTo가 반환하는 값은 -1, 0, 1이 아니라 음수, 0, 양수이다.
    * _2020-11-20(금)_
        * 유니온 파인드는 집합을 나타낼 때 주로 사용한다.(합집합)
        
    * _2021_03_08(월)_
        * KMP : 문자열 S가 있을 때, 패턴 P를 찾는 알고리즘
        * Trie : 문자열 N개가 있을 때, 문자열 S를 찾는 알고리즘
            * 출석부에서 내 이름 찾기
        * Aho-corasick : 문자열 N개가 있을 때, 패턴 P를 찾는 알고리즘
            * 출석부에 나랑 성(이름)이 같은 사람 찾기
            * Aho-corasick에서 fail[node] = node가 나타내는 문자열 s의 suffix이면서 trie에 포함된 가장 긴 문자열
            * KMP의 fail[node]와는 다르게 BFS 방식으로 fail[node]를 구한다.
            
    * _2021_03_11(목)_
        * 다이나믹 프로그래밍에서 "모른다"는 정보는 굉장히 중요하다.
        * nextPermutation, lowerBound, upperBound, KMP 알고리즘
    
    * _2021_04_25(일)_
        * DAG : Directed Acyclic Graph. 사이클이 없는 방향 그래프이다. 선행 관계에서 사용한다.
        * 위상 정렬 : 그래프의 간선 u->v가 u가 v보다 먼저라는 의미일 때 정점의 순서를 찾는 알고리즘이다. BFS를 응용해서 구현할 수 있다.
            * 순서에 추가되는 정점은 in-degree가 0일 때로 표현할 수 있다. 선행 조건을 다 만족했다는 의미. 따라서 in-degree가 0일 때 큐에 넣는다.
            * ind[] 배열로 in-degree를 관리한다. ind[i]가 0일 때 큐에 넣는다. 그리고 BFS를 진행하면서 모든 간선에 대해 1씩 감소시킨다. 간선을 지우는 것은 아무 의미가 없다. 해당 간선을 사용했다는 의미로 지웠다고 표현하는 것이다.
            * DFS로도 구현할 수 있다. 그래프의 간선을 모두 뒤집어놓고 DFS를 수행하고 정점이 스택에서 빠져나오는 순서를 기록하면 위상 정렬의 순서와 같아진다.
        * MST : Minimum spanning tree. 그래프를 트리로 만들 때 일부 간선을 선택해서 만든 것을 스패닝 트리라고 한다. 스패닝 트리 중 선택한 간선의 가중치의 합이 최소인 트리를 MST라고 한다. MST를 찾는 방법은 프림, 크루스칼 등이 있다. 가장 중요한 것은 사이클을 만들지 않는 것이다. 트리는 사이클이 없기 때문이다.
            * 프림(Prim) : 1. 그래프에서 아무 정점이나 선택한다. 2. 모든 간선 중 선택한 정점과 선택하지 않은 정점 사이의 가장 낮은 가중치의 간선을 찾는다. 3. 이를 V-1번 반복한다. 시간 복잡도는 O(V*E)이다. 최대 O(V^3). 우선순위 큐를 쓰면 O(E log V)로 줄일 수 있다.
                * 필요한 정보는 to와 cost이다. from은 이미 선택됐기 때문이다. to가 이미 선택된 정점이면 그냥 continue하면 된다.
            * 크루스칼(kruskal) : 유니온 파인드를 이용한다. 작은 가중치의 간선 순으로 정렬한다. 그 후 MST에 포함시킬 지 안시킬 지 판단한다. 이 때 쓰는 것이 유니온 파인드이다. 같은 그룹인지 아닌지 판단한다. 시간 복잡도는 O(E log E)이다. O(E)에 정렬이 O(log E)가 걸리기 때문이다.
                * 크루스칼에서는 간선의 양 끝 점 정보가 모두 필요하므로 from, to, cost를 사용한다.
            * 프림과 크루스칼 : 프림은 정점을 기준으로 계속 추가하는 방식이고 크루스칼은 간선을 계속 추가하면서 만드는 방식이다.
    
    * _2021_04_28(수)_
        * 최단 경로 : 시작점이 1개일 때, 다른 모든 곳으로 가는 최단 경로(Single Source Shortest Path)
          살면서 가장 많이 겪게 되는 알고리즘 문제일 것이다. A에서 B로 가는 최단 경로는 그래프의 정점이 N개라고 한다면 N-1개의 간선으로 이루어져 있다. A와 B 사이에 N-2개의 정점이 들어간다.
            * 벨만포드 : 위 성질을 그대로 이용하는 알고리즘이다. from->to의 가중치가 cost. dist[i]에 시작점->i 최단경로를 기록했다고 한다면 dist[to] > dist[from] + cost 일 경우 갱신한다. 이 검사를 최대 N-1번 반복하는 것이 벨만포드 알고리즘이다. 모든 간선에 대해 검사하므로 O(E)에 정점이 V개이므로 시간 복잡도는 O(VE)이다. E는 최대 V^2이므로 O(B^3)으로 봐도 무방하다.
                * 벨만포드는 느린 알고리즘이라 잘 사용하지 않는다. 유일하게 가중치가 음수일 때의 최단경로를 구할 때 사용한다.
                * 벨만포드는 전체를 훑어보는 알고리즘이라서 인접 행렬, 리스트를 사용하지 않고 1차원 배열에 저장한다.
                * 음수 사이클을 찾으려면 벨만포드의 n-1번 반복을 n번 반복으로 바꿔주면 된다. 왜냐하면 간선이 N-1개 이하로만 이루어져 있어야 하는데 간선을 N개 사용한 경우까지 검사한 것이므로 이 결과가 다르면 음수 사이클이 존재하는 경우이다. 따라서 n번째에 최단 코스트가 바뀌면 음수 사이클이다.
            * 다익스트라 : V^2 또는 E log E에 구할 수 있는 알고리즘이다. 2가지가 필요하다. dist[i] = 시작->i의 최단 거리, check[i] = i를 검사했으면 true, 아니면 false
                * 시작점에서 갈 수 있는 정점을 검사하고 dist[i]를 업데이트한다. 그리고 dist[i]가 가장 낮고 check가 안되어있는 정점으로 이동한다. 이 과정을 반복한다.
                * 시간 복잡도는 모든 정점이 1번씩 선택되므로 O(V)에 각 정점을 한 번씩 돌아야하므로 O(V)여서 O(V^2)이다.
                * 맨 마지막 정점은 선택할 필요가 없다. 모든 최단 거리는 V-1개로 이루어져 있기 때문이다.
                * 역추적, 즉 경로도 구할 수 있다. 거의 대부분이 경로를 구할 때는 어떤 값이 언제 바꼈는지 알아내면 된다. BFS나 DP 등등.
                * 시간 복잡도를 O(E log E)로 줄이는 방법을 알아보자. 최소 거리를 가진 정점을 찾는 부분을 줄이면 된다. 알고리즘의 시간 복잡도를 줄이는 방법에는 주로 과정에서 최소나 최대를 찾을 때 우선순위 큐를 쓰거나 세그먼트 트리를 쓰는 방법이 있다. 우선순위 큐는 어딘가에 몰아 놓고 거기서 최소/최대를 찾는 것. 세그먼트 트리는 구간이 있고, 구간에서 최소/최대를 찾을 때 쓴다.
                    * 여기서는 우선순위 큐에 D[i]와 i를 같이 저장한다. 값이 계속 바뀌기 때문이다.
                    * 이를 또 O(E log V)로 줄일 수 있다. 힙에 같은 값을 저장하지 않게 하면 된다. (3, 5)와 (5, 5)일 경우 (5, 5)를 (3, 5)로 바꿔주면 된다. 여기에는 다른 자료구조를 쓰면 된다. set을 쓰면 된다. 하지만 둘이 비슷하므로 구현이 편한 E log E 방식을 쓴다.
    
    
    
    
        
* 다시 봐야 할 것
    * Q14391. 종이 조각 : https://www.acmicpc.net/problem/14391
    * Q16947. 서울 지하철 2호선 : https://www.acmicpc.net/problem/16947
    * Q15663. N과 M (9) : https://www.acmicpc.net/problem/15663
    * Q9019. DSLR : https://www.acmicpc.net/problem/9019 (시간복잡도 개선)
    * Q2206. 벽 부수고 이동하기 : https://www.acmicpc.net/problem/2206 (시간복잡도 개선)
    * Q2447. 별 찍기 - 10 : www.acmicpc.net/problem/2447
